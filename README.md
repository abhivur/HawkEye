# HawkEye 
## Smart Drone Flight Planning System
### By Luke Voinov and Abhinav Vurakaranam

Thank you to Dr. Camp for teaching ECE 5393 091: Drone Communications at SMU in Taos!

### Results Folder
Contains KML files for each route. Enhanced analysis JSON files analyze flight footage to find where people were detected, then creates a 4-point adaptive waypoint plan around that location for focused reinspection. Drone footage files identify likely human locations from drone footage and generates a focused 4-waypoint re-survey plan centered on the detected person. Finally a PNG which shows the optimized flight route + heatmap.

### frameSplitting.py
Uses OpenCV to take a video as input and output each frame (currently set to every 30th frame since our test drone footage was captured at 30 fps).

### YOLO&Embeddings.py
Takes the split frames generated by the previous code and runs each one through YOLOv8 small. This YOLO is pretrained on 80 classes from the COCO dataset.
The output is a .json that details each object found in each frame.

### map-aware-v2-HawkEye.py
Input: the object .json from the previous code, user original drone flight path (.kml), and user objective (str)
Ouput: Drone flight path that satisfies user objective. See results folder.

Example objectives / queries:

✅ "Find people in this area" → Object search map with numbered waypoints

✅ "Survey 15 meters around this path" → Corridor survey map

✅ "Where are vehicles most likely?" → Vehicle-focused search map

✅ "Locate furniture and benches" → Multi-object search patterns
